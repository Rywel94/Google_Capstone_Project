---
title: "Google Capstone Project - Cyclistic Case Study"
author: "R Welsh"
date: "2024-09-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The Background 
###  Scenario
You are a junior data analyst working on the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore,your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve your recommendations, so they must be backed up with compeling data insights and professional data visualizations.

### The Stakeholders and Teams
Cyclistic: A bike-share program that features more than 5,800 bicycles and 600
docking stations. Cyclistic sets itself apart by also offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can’t use a standard two-wheeled bike. The majority of riders opt for traditional bikes; about 8% of riders use the assistive options. Cyclistic users are more likely to ride for leisure, but about 30% use the bikes to commute to work each day.

Lily Moreno: The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program.These may include email, social media, and other channels.

Cyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy. You joined this team six months ago and have been busy learning about Cyclistic’s mission and business goals— aswell as how you, as a junior data analyst, can help Cyclistic achieve them.


Cyclistic executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.

### Company Overview
In 2016, Cyclistic launched a successful bike-share ordering service. Since then, the program has grown to a fleet of 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.

Until now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the exibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders.Customers who purchase annual memberships are Cyclistic members. Cyclistic’s analysts have concluded that annual members are much more profitable than casual riders. Although the pricing exibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets new customers, Moreno believes
there is a solid opportunity to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs. 

Moreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends.

## My Role 
Moreno has assigned me to see how annual members and casual members differ in their use of the service.

## How will I do this
First thing I will need to do is get a dataset that will be used to help my derive analysis to therfore make a report on my findings.  

## Gathering the datasets required for my analyis 
As Cyclistic is a "mock" company there is no first party data so I gathered the datasets required for this project from this link <https://divvy-tripdata.s3.amazonaws.com/index.html>. This data has been made available from Motivate International Inc Under the license <https://divvybikes.com/data-license-agreement> The datasets I have selected are the previous 12 months (2023-09-divvy-tripdata - 2024-08-2024-divvy-tripdata) these datasets cover recent data which will give me more insight into the current consumer market which will be more benefical to the company as my recommendations will be based on more reliable data than if I used a past dataset from a previous year i.e 2005. This will also give a better indication to the marketing team for what type of indicators they will need to target.

## Preparing and Cleaning the data
After downloading and unzipping the datasets required I then converted all file types from CSV to XLS and then opened each spreadsheet in Excel and checked for duplicated values among the data, No duplicated values were found therefore the remove duplicates function didn't need to be used. 

## Individual Sheet Analysis

### Start of the analysis

I went through all of the datasets and decided to find the mean, the mode, the max and the min of the rides. 


I then added a weekday function in order to view the day the rides were made as this could be a way to differentiate how the types of user use the service. I then added a mode function to see what day was the most common.


I then made pivot tables, visualisations and a overall Dashboard for each dataset to find and showcase the difference between Annual and Casual users. The 5 metrics I wanted to view was average ride length between the two members, the average ride length by day, the amount of use per member per day, The most common bike type by member and the average ride length by member per bike type. 

The spreadsheets are able to be viewed on my portfolio

## Using R to Merge and Produce further analysis

First thing to do when opening R is to open the packages I will need to provide analysis on the data

```{r}
library(tidyverse)
library(readxl)
library(janitor)
library(skimr)
library(flexdashboard)
```

```{r}
library(tinytex)
```

To start my analysis in R I have to import the data so I will change my working directory in R to where the raw csv files are held

```{r} 
setwd("C:/Documents/Google Capstone Project/Cyclistic Case Study")
```

Then I imported the datasets

``` {r}
sep_23 <- read.csv("202309-divvy-tripdata.csv")
```

``` {r}
oct_23 <- read.csv("202310-divvy-tripdata.csv")
```

``` {r}
nov_23 <- read.csv("202311-divvy-tripdata.csv")
```

``` {r}
dec_23 <- read.csv("202312-divvy-tripdata.csv")
```

``` {r}
jan_24 <- read.csv("202401-divvy-tripdata.csv")
```

``` {r}
feb_24 <- read.csv("202402-divvy-tripdata.csv")
```

``` {r}
mar_24 <- read.csv("202403-divvy-tripdata.csv")
```

``` {r}
apr_24 <- read.csv("202404-divvy-tripdata.csv")
```

``` {r}
may_24 <- read.csv("202405-divvy-tripdata.csv")
```

``` {r}
jun_24 <- read.csv("202406-divvy-tripdata.csv")
```

``` {r}
jul_24 <- read.csv("202407-divvy-tripdata.csv")
```

``` {r}
aug_24 <- read.csv("202408-divvy-tripdata.csv")
```


### Next Steps

View the datasets to see if they've imported correctly 

``` {r}
View(sep_23)
```

``` {r}
View(oct_23)
```

``` {r}
View(nov_23)
```

``` {r}
View(dec_23)
```

``` {r}
View(jan_24)
```

``` {r}
View(feb_24)
```

``` {r}
View(mar_24)
```

``` {r}
View(apr_24)
```

``` {r}
View(may_24)
```

``` {r}
View(jun_24)
```

``` {r}
View(jul_24)
```

``` {r}
View(aug_24)
```

check the column names of the datasets 

``` {r}
colnames(sep_23)
```

```{r}
colnames(oct_23)
```

```{r}
colnames(nov_23)
```

```{r}
colnames(dec_23)
```

```{r}
colnames(jan_24)
```

```{r}
colnames(feb_24)
```

```{r}
colnames(mar_24)
```

```{r}
colnames(apr_24)
```

```{r}
colnames(may_24)
```

```{r}
colnames(jun_24)
```

```{r}
colnames(jul_24)
```

```{r}
colnames(aug_24)
```

```{r}
head(sep_23)
```

```{r}
head(oct_23)
```

```{r}
head(nov_23)
```

```{r}
head(dec_23)
```

```{r}
head(jan_24)
```

```{r}
head(feb_24)
```

```{r}
head(mar_24)
```

```{r}
head(apr_24)
```

```{r}
head(may_24)
```

```{r}
head(jun_24)
```

```{r}
head(jul_24)
```

```{r}
head(aug_24)
```

I still need to amend and delete some column's in order to make the files workable when I merge them together.

## Merging the datasets

Now it is time to merge the two datasets together into a new dataframe

```{r}
all_trips <- bind_rows(sep_23, oct_23, nov_23, dec_23, jan_24, feb_24, mar_24, apr_24, may_24, jun_24, jul_24, aug_24)
```

This has now created a new dataset called all_trips which I will view 

```{r}
View(all_trips)
```

check the columns are correct

```{r}
colnames(all_trips)
```
And check the rows and columns have stacked correctly 

```{r}
head(all_trips)
```
As you can see some columns mainly start and end station are only referenced in some datasets and some columns I will not need to produce my report therefore I will need to clean this new dataframe before beginning analysis. 

#### Removing Columns I will not need 

```{r}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng, start_station_name, start_station_id, end_station_name, end_station_id))
```

### Time to Inspect my New Dataframe

Now it's time to inspect my new Dataframe.

```{r}
View(all_trips)
```

```{r}
colnames(all_trips)  #List of column names
```

```{r}
nrow(all_trips)  #How many rows are in data frame?
```

```{r}
dim(all_trips)  #Dimensions of the data frame?
```

```{r}
head(all_trips)  #See the first 6 rows of data frame.
```

```{r}
str(all_trips)  #See list of columns and data types (numeric, character, etc)
```

```{r}
tail(all_trips)
```

```{r}
summary(all_trips)  #Statistical summary of data. Mainly for numerics
```
## Further Actions 

I need to introduce columns I had for the individual spreadsheets (Weekday, Ride Length, Mean Ride, Max Ride, Min Ride) as well as create new columns i.e Day, Month, Year so that I am able to further aggregate the data.

### Adding the Date,Month,Year,Day to each ride

The reason I want to add this to the Dataframe is in order to be able to gain more opportunities to aggragate the data.

```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
```

```{r}
all_trips$month <- format(as.Date(all_trips$date), "%m") # Month
```

```{r}
all_trips$day <- format(as.Date(all_trips$date), "%d") # Day
```

```{r}
all_trips$year <- format(as.Date(all_trips$date), "%Y") # Year
```

```{r}
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A") # Day of Week
```

Now my Dataframe looks like this,

```{r}
head(all_trips)
```

### Adding the Ride Length (in Seconds)
```{r}
all_trips$started_at <- ymd_hms(all_trips$started_at)
all_trips$ended_at <- ymd_hms(all_trips$ended_at)


# Calculate diff time
all_trips$ride_length <- difftime(
    all_trips$ended_at,
    all_trips$started_at,
    units = "secs"
    )
```

Then I will inspect the structure of the column

```{r}
str(all_trips)
```

I need to make sure the column for ride_length isn't in factor form, I need this to be numeric if I wish to make calculations such as mean,median, mode later on. 

```{r}
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```

### Removing Bad Data

As I had previously found from the individual spreadsheets there are rides that have either negative or had 0 sec rides, These rides are either Quality Control on behalf of Cyclistic or errors, I will remove these rides for my analysis   

```{r}
all_trips_v2 <- all_trips[!(all_trips$ride_length<1),] # This will remove all rides that are negative or are under 1 second
```

## Time to Anaylse the Data

Descriptive analysis on ride_length (all figures in seconds)


```{r}
summary(all_trips_v2) # Overall Summary of the data
```

```{r}
mean(all_trips_v2$ride_length) # Mean of the ride length
```

```{r} 
total_ride_length <- sum(all_trips_v2$ride_length, na.rm = TRUE) 

number_of_rides <- nrow(all_trips_v2) 

average_ride_length <- total_ride_length / number_of_rides

print(average_ride_length) # This chuck of code will get the Average ride length
```

```{r}
median(all_trips_v2$ride_length) # Median ride length
```

```{r}
max(all_trips_v2$ride_length) # Longest ride
```

```{r}
min(all_trips_v2$ride_length) # Shortest ride
```

## Time to compare Members and Casuals

Now it's time to see the difference using these metrics between the two userbases

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean) # The mean between the two userbases
```


```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
# The Median between the two userbases
```


```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
# The longest ride between the two userbases
```


```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
# The shortest ride between the two userbases
```


```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean) # The Average ride time by day by each userbase
```


The days of the week are out of order making this data harder to understand I need to write the below code to fix this issues

```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

Now I will try to find the average ride time by userbase on a daily basis
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```


This looks much clearer to read and understand. 

### Lets Analyse the Userbase by Weekday

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
            ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)	# sorts the data 
```

## Time to Visualise this 

### The Below Graph shows the number of rides by userbase

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```


### The Below graph shows the average duration by userbase
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

### The Rideable Type by Member Type

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday, rideable_type) %>% 
  summarise(number_of_rides = n(), 
            average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday) %>% 
  ggplot(aes(x = rideable_type, y = number_of_rides, fill = member_casual)) + 
  geom_col(position = "dodge")
```

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday, rideable_type) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = rideable_type, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

## Summary

The Graphs currently displayed show the annual user use of the service is higher than the causal user on a daily basis. 

However you can see an underlying trend between the two types. 

The annual users seems to have an upward trajectory through the working week with a tail off on the weekend,This is most likely due to the trips took by annual members are commutes to work or to events. 

The casual users use is lower through the week with the highest peak of users being on the weekend. The rides of a casual user is on average longer than a annual rider regardless of what day the ride is made. this is most likely less frequent but long bike rides from a user when they are off work. 

The type of bike that is ridden seems to be equal between the two users but the average duration on a docked bike by a casual user seems to point that a causal user prefers to use this type of bike when doing a long bike ride on the weekend.

### Suggestions Based on this

For an Weekend only annual membership. this may have get casual users who only use the service on a weekend to be more inclined to a subscription model.

Monthly or Bi Monthly passes with a set number of hours linked to the pass i.e 1 Month 35 Hours, 2 Months 80 Hours. This may get causal users who will use the service for long durations of time on a weekend to pay upfront but not have the fear of being in an annual subscription model initially. this may In turn make them use the service during the week which may make them reconsider an annual subscription. 

A long rider membership which will only be applicable to docked bikes as these seem to be the choice of bike casual users prefer when going for long rides.  

### Further Visualisation / Analysis 
I am going to create a CSV file with this dataframe that I then perform more visualisations using tableau <https://public.tableau.com/app/profile/ryan.welsh6016/vizzes>
